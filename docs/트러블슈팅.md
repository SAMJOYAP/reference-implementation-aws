# íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ

> ì‹¤ì œ ë°°í¬ ê³¼ì •ì—ì„œ ë°œìƒí•œ ë¬¸ì œë“¤ê³¼ í•´ê²° ë°©ë²•ì„ ì •ë¦¬í•œ ì‹¤ì „ ê°€ì´ë“œì…ë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨

1. [ë¹ ë¥¸ ì§„ë‹¨](#1-ë¹ ë¥¸-ì§„ë‹¨)
2. [Backstage ë¬¸ì œ](#2-backstage-ë¬¸ì œ)
3. [External Secrets ë¬¸ì œ](#3-external-secrets-ë¬¸ì œ)
4. [Ingress & LoadBalancer ë¬¸ì œ](#4-ingress--loadbalancer-ë¬¸ì œ)
5. [ì¸ì¦ì„œ(Certificate) ë¬¸ì œ](#5-ì¸ì¦ì„œcertificate-ë¬¸ì œ)
6. [Keycloak & PostgreSQL ë¬¸ì œ](#6-keycloak--postgresql-ë¬¸ì œ)
7. [DNS ë¬¸ì œ](#7-dns-ë¬¸ì œ)
8. [Argo CD ë¬¸ì œ](#8-argo-cd-ë¬¸ì œ)
9. [ì¼ë°˜ì ì¸ ë””ë²„ê¹… ë°©ë²•](#9-ì¼ë°˜ì ì¸-ë””ë²„ê¹…-ë°©ë²•)

---

## 1. ë¹ ë¥¸ ì§„ë‹¨

### ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸

```bash
# 1. All Applications ìƒíƒœ
kubectl get applications -n argocd -o custom-columns='NAME:.metadata.name,SYNC:.status.sync.status,HEALTH:.status.health.status'

# 2. ëª¨ë“  Pods ìƒíƒœ
kubectl get pods -A | grep -v "Running" | grep -v "Completed"

# 3. Ingresses í™•ì¸
kubectl get ingress -A

# 4. Certificates í™•ì¸
kubectl get certificate -A

# 5. ExternalSecrets í™•ì¸
kubectl get externalsecret -A
```

### ë¬¸ì œ ìˆëŠ” ë¦¬ì†ŒìŠ¤ ì°¾ê¸°

```bash
# Healthê°€ Degradedì¸ Applications
kubectl get applications -n argocd -o json | \
  jq -r '.items[] | select(.status.health.status != "Healthy") | .metadata.name'

# Readyê°€ ì•„ë‹Œ Pods
kubectl get pods -A --field-selector=status.phase!=Running,status.phase!=Succeeded

# Readyê°€ Falseì¸ Certificates
kubectl get certificate -A -o json | \
  jq -r '.items[] | select(.status.conditions[]?.type=="Ready" and .status.conditions[]?.status=="False") | "\(.metadata.namespace)/\(.metadata.name)"'
```

---

## 2. Backstage ë¬¸ì œ

### 2.1 CrashLoopBackOff - Missing webhookSecret

#### ì¦ìƒ

```bash
$ kubectl get pods -n backstage
NAME                        READY   STATUS             RESTARTS   AGE
backstage-xxx-yyy           0/1     CrashLoopBackOff   5          10m

$ kubectl logs -n backstage -l app.kubernetes.io/name=backstage
Error: Missing required config value at 'integrations.github[0].apps[0].webhookSecret' in 'env'
```

#### ì›ì¸

AWS Secrets Managerì˜ `backstage-github.webhookSecret` ê°’ì´ ë¹ˆ ë¬¸ìì—´(`""`)ì´ê±°ë‚˜ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.

**BackstageëŠ” webhookì„ ë¹„í™œì„±í™”í•´ë„ `webhookSecret` í•„ë“œë¥¼ í•„ìˆ˜ë¡œ ìš”êµ¬í•©ë‹ˆë‹¤.**

#### í•´ê²° ë°©ë²•

```bash
# 1. í˜„ì¬ AWS Secrets Manager ê°’ í™•ì¸
aws secretsmanager get-secret-value \
  --secret-id cnoe-ref-impl/github-app \
  --region $(yq '.region' config.yaml) \
  --query 'SecretString' --output text | \
  jq -r '.["backstage-github"].webhookSecret'

# ë¹ˆ ë¬¸ìì—´ì´ë©´ ìˆ˜ì • í•„ìš”

# 2. ë¡œì»¬ íŒŒì¼ ìˆ˜ì •
vi private/backstage-github.yaml
```

**ì˜¬ë°”ë¥¸ ê°’:**

```yaml
webhookSecret: "dummy-webhook-secret-not-used"  # â† ì´ ì •í™•í•œ ê°’ ì‚¬ìš©!
```

**ì˜ëª»ëœ ê°’ë“¤:**

```yaml
webhookSecret: ""                    # âŒ ë¹ˆ ë¬¸ìì—´
webhookSecret:                       # âŒ ê°’ ì—†ìŒ
webhookSecret: "your-webhook-secret" # âŒ ì‹¤ì œ ì‹œí¬ë¦¿ (webhook ë¹„í™œì„±í™” ì‹œ)
```

```bash
# 3. AWS Secrets Manager ì—…ë°ì´íŠ¸
./scripts/create-config-secrets.sh
# ì…ë ¥: yes

# 4. Kubernetes Secret ê°•ì œ ë™ê¸°í™”
kubectl delete secret integrations -n backstage

# 5. ë™ê¸°í™” í™•ì¸ (2-3ì´ˆ í›„)
kubectl get secret integrations -n backstage -o jsonpath='{.data.github-integration\.yaml}' | \
  base64 -d | grep webhookSecret
# ì¶œë ¥: webhookSecret: dummy-webhook-secret-not-used

# 6. Pod ì¬ì‹œì‘
kubectl delete pod -n backstage -l app.kubernetes.io/name=backstage

# 7. í™•ì¸
kubectl get pods -n backstage
# NAME                        READY   STATUS    RESTARTS   AGE
# backstage-xxx-yyy           1/1     Running   0          30s
```

### 2.2 Backstage PostgreSQL ì´ë¯¸ì§€ Pull ì‹¤íŒ¨

#### ì¦ìƒ

```bash
$ kubectl get pods -n backstage
NAME                              READY   STATUS         RESTARTS   AGE
backstage-postgresql-0            0/1     ErrImagePull   0          5m

$ kubectl describe pod -n backstage backstage-postgresql-0
Events:
  Failed to pull image "docker.io/bitnami/postgresql:latest":
  manifest for docker.io/bitnami/postgresql:latest not found
```

#### ì›ì¸

Bitnamiê°€ ë ˆê±°ì‹œ ì´ë¯¸ì§€ë¥¼ `bitnamilegacy` ë ˆì§€ìŠ¤íŠ¸ë¦¬ë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤.

#### í•´ê²° ë°©ë²•

```bash
# 1. values.yaml í™•ì¸
grep -A 3 "repository:" packages/backstage/values.yaml

# 2. ìˆ˜ì • (ì•„ì§ ì•ˆë˜ì–´ ìˆë‹¤ë©´)
sed -i.bak 's|repository: bitnami/postgresql|repository: bitnamilegacy/postgresql|g' \
  packages/backstage/values.yaml

# 3. Git commit & push
git add packages/backstage/values.yaml
git commit -m "Fix: Use bitnamilegacy registry for PostgreSQL"
git push origin main

# 4. Application ì¬ë™ê¸°í™” (Argo CDê°€ ìë™ìœ¼ë¡œ ìˆ˜í–‰í•˜ê±°ë‚˜ ìˆ˜ë™)
kubectl delete application -n argocd backstage-$(yq '.cluster_name' config.yaml)
```

---

## 3. External Secrets ë¬¸ì œ

### 3.1 ExternalSecret - SecretSyncedError (Region Mismatch)

#### ì¦ìƒ

```bash
$ kubectl get externalsecret -A
NAMESPACE   NAME               STORE                REFRESH   STATUS             READY
backstage   integrations       aws-secretsmanager   0         SecretSyncedError  False
argocd      hub-cluster-secret aws-secretsmanager   0         SecretSyncedError  False

$ kubectl describe externalsecret integrations -n backstage
Error: AccessDeniedException: Secrets Manager can't find the specified secret in us-west-2
```

#### ì›ì¸

ClusterSecretStoreê°€ ì˜ëª»ëœ AWS ë¦¬ì „(us-west-2)ì„ ì°¸ì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤.

#### í•´ê²° ë°©ë²•

```bash
# 1. í˜„ì¬ ë¦¬ì „ í™•ì¸
kubectl get clustersecretstore aws-secretsmanager \
  -o jsonpath='{.spec.provider.aws.region}'
# ì¶œë ¥: us-west-2  â† ì˜ëª»ëœ ë¦¬ì „

# 2. ì˜¬ë°”ë¥¸ ë¦¬ì „ìœ¼ë¡œ íŒ¨ì¹˜
export AWS_REGION=$(yq '.region' config.yaml)
kubectl patch clustersecretstore aws-secretsmanager \
  --type='json' \
  -p="[{\"op\": \"replace\", \"path\": \"/spec/provider/aws/region\", \"value\":\"$AWS_REGION\"}]"

# 3. External Secrets Operator ì¬ì‹œì‘
kubectl rollout restart deployment external-secrets -n external-secrets

# 4. ëª¨ë“  ExternalSecrets ê°•ì œ ë™ê¸°í™”
kubectl annotate externalsecret -A --all force-sync=$(date +%s) --overwrite

# 5. í™•ì¸
kubectl get externalsecret -A
# ëª¨ë“  ExternalSecretì˜ READYê°€ Trueì—¬ì•¼ í•¨
```

**ì˜ˆë°©ì±…: ì„¤ì¹˜ ì „ì— ì˜¬ë°”ë¥¸ ë¦¬ì „ ì„¤ì •**

```bash
# packages/external-secrets/manifests/cluster-secret-store.yaml ìˆ˜ì •
sed -i.bak "s/us-west-2/$AWS_REGION/g" \
  packages/external-secrets/manifests/cluster-secret-store.yaml

# Git commit
git add packages/external-secrets/manifests/cluster-secret-store.yaml
git commit -m "Configure ClusterSecretStore for region $AWS_REGION"
```

### 3.2 ExternalSecret - SecretSyncedError (IAM Permission)

#### ì¦ìƒ

```bash
$ kubectl logs -n external-secrets deployment/external-secrets --tail=50
AccessDeniedException: User: arn:aws:sts::123456789012:assumed-role/xxx
is not authorized to perform: secretsmanager:GetSecretValue on resource: cnoe-ref-impl/github-app
```

#### ì›ì¸

External Secrets ServiceAccountì— ì—°ê²°ëœ IAM Roleì— ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.

#### í•´ê²° ë°©ë²•

```bash
# 1. ServiceAccountì˜ IAM Role í™•ì¸
kubectl get sa external-secrets -n external-secrets -o yaml | \
  grep eks.amazonaws.com/role-arn

# 2. IAM Role ê¶Œí•œ í™•ì¸
aws iam get-role-policy \
  --role-name <ROLE_NAME> \
  --policy-name <POLICY_NAME>

# 3. í´ëŸ¬ìŠ¤í„° ì¬ìƒì„± (í•„ìš”í•œ ê²½ìš°)
# ë˜ëŠ” EKS Pod Identity Association ì¬ìƒì„±
```

### 3.3 hub-cluster-secret ìƒì„± ì•ˆë¨

#### ì¦ìƒ

```bash
$ kubectl get secrets -n argocd -l argocd.argoproj.io/secret-type=cluster
No resources found in argocd namespace.

# ì´ë¡œ ì¸í•´ Applicationsê°€ ìƒì„±ë˜ì§€ ì•ŠìŒ
$ kubectl get applications -n argocd
NAME                              SYNC STATUS   HEALTH STATUS
addons-appset-pr-xxx              Synced        Healthy
# ë‚˜ë¨¸ì§€ Applications ì—†ìŒ
```

#### ì›ì¸

`hub-cluster-secret` ExternalSecretì´ Secretì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.

#### í•´ê²° ë°©ë²•

```bash
# 1. ExternalSecret ìƒíƒœ í™•ì¸
kubectl describe externalsecret hub-cluster-secret -n argocd

# 2. ExternalSecret ì¬ìƒì„±
kubectl delete externalsecret hub-cluster-secret -n argocd
kubectl apply -f packages/argo-cd/manifests/hub-cluster-secret.yaml

# 3. Secret ìƒì„± í™•ì¸
kubectl get secret -n argocd -l argocd.argoproj.io/secret-type=cluster

# 4. Argo CD ApplicationSet Controller ì¬ì‹œì‘
kubectl rollout restart deployment argocd-applicationset-controller -n argocd

# 5. Applications ìƒì„± í™•ì¸
kubectl get applications -n argocd
```

---

## 4. Ingress & LoadBalancer ë¬¸ì œ

### 4.1 Ingress ADDRESS ë¹„ì–´ìˆìŒ

#### ì¦ìƒ

```bash
$ kubectl get ingress -A
NAMESPACE   NAME                    HOSTS               ADDRESS   PORTS
backstage   backstage               myapp.example.com   <none>    80, 443
```

#### ì›ì¸

AWS Load Balancer Controllerê°€ ì •ìƒ ë™ì‘í•˜ì§€ ì•Šê±°ë‚˜ ALB ìƒì„± ì¤‘ì…ë‹ˆë‹¤.

#### í•´ê²° ë°©ë²•

```bash
# 1. LB Controller ìƒíƒœ í™•ì¸
kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller

# 2. LB Controller ë¡œê·¸ í™•ì¸
kubectl logs -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller --tail=100

# 3. IngressClass í™•ì¸
kubectl get ingressclass
# NAME    CONTROLLER             PARAMETERS   AGE
# nginx   k8s.io/ingress-nginx   <none>       10m

# 4. Ingress ì¬ìƒì„±
kubectl delete ingress -A --all

# 5. ingress-nginx Application ì¬ë™ê¸°í™”
kubectl delete application -n argocd ingress-nginx-$(yq '.cluster_name' config.yaml)
# Argo CDê°€ ìë™ìœ¼ë¡œ ì¬ìƒì„±

# 6. ALB ìƒì„± í™•ì¸ (5-10ë¶„ ì†Œìš”)
watch -n 10 'kubectl get ingress -A'
```

### 4.2 AWS Load Balancer Controller Pod ì‹œì‘ ì‹¤íŒ¨

#### ì¦ìƒ

```bash
$ kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller
NAME                                       READY   STATUS    RESTARTS   AGE
aws-load-balancer-controller-xxx-yyy       0/1     Error     3          5m
```

#### ì›ì¸

IAM Role ê¶Œí•œ ë¶€ì¡± ë˜ëŠ” OIDC Provider ë¯¸ì„¤ì •

#### í•´ê²° ë°©ë²•

```bash
# 1. ë¡œê·¸ í™•ì¸
kubectl logs -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller

# 2. OIDC Provider í™•ì¸
aws eks describe-cluster \
  --name $(yq '.cluster_name' config.yaml) \
  --region $(yq '.region' config.yaml) \
  --query "cluster.identity.oidc.issuer" \
  --output text

# 3. OIDC Provider ì—°ê²° (ì—†ë‹¤ë©´)
eksctl utils associate-iam-oidc-provider \
  --cluster $(yq '.cluster_name' config.yaml) \
  --region $(yq '.region' config.yaml) \
  --approve

# 4. Pod ì¬ì‹œì‘
kubectl rollout restart deployment aws-load-balancer-controller -n kube-system
```

---

## 5. ì¸ì¦ì„œ(Certificate) ë¬¸ì œ

### 5.1 Certificate Pending (DNS Challenge Failed)

#### ì¦ìƒ

```bash
$ kubectl get certificate -A
NAMESPACE   NAME             READY   SECRET           AGE
backstage   backstage-tls    False   backstage-tls    10m

$ kubectl describe certificate backstage-tls -n backstage
Reason: Waiting for HTTP-01 challenge propagation:
failed to perform self check GET request: dial tcp: lookup myapp.example.com: no such host
```

#### ì›ì¸

DNS ì „íŒŒê°€ ì™„ë£Œë˜ì§€ ì•Šì•˜ê±°ë‚˜ Route53 ë ˆì½”ë“œê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.

#### í•´ê²° ë°©ë²•

```bash
# 1. DNS ì „íŒŒ í™•ì¸
dig myapp.example.com +short
# ALBì˜ IP ì£¼ì†Œê°€ ë‚˜ì™€ì•¼ í•¨

# 2. Route53 ë ˆì½”ë“œ í™•ì¸
aws route53 list-resource-record-sets \
  --hosted-zone-id $(yq '.route53_hosted_zone_id' config.yaml) | \
  jq '.ResourceRecordSets[] | select(.Name | contains("myapp"))'

# 3. External DNS ë¡œê·¸ í™•ì¸
kubectl logs -n external-dns deployment/external-dns --tail=50

# 4. External DNS ì¬ì‹œì‘ (í•„ìš”ì‹œ)
kubectl rollout restart deployment external-dns -n external-dns

# 5. DNS ì „íŒŒ ëŒ€ê¸° (1-5ë¶„)
watch -n 10 "dig myapp.example.com +short"

# 6. Certificate ì¬ì‹œë„ (ìë™ìœ¼ë¡œ ì¬ì‹œë„ë¨)
kubectl get certificate -A -w
```

### 5.2 Certificate Rate Limit (Let's Encrypt)

#### ì¦ìƒ

```bash
$ kubectl describe certificate backstage-tls -n backstage
Reason: Error accepting authorization: acme: authorization error for myapp.example.com:
429 urn:ietf:params:acme:error:rateLimited: too many certificates already issued for exact set of domains
```

#### ì›ì¸

Let's Encrypt Rate Limitì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.

#### í•´ê²° ë°©ë²•

**ì˜µì…˜ 1: Staging Issuer ì‚¬ìš© (í…ŒìŠ¤íŠ¸)**

```bash
# Staging issuerë¡œ ë³€ê²½ (Rate Limit ì—†ìŒ, ë‹¨ ë¸Œë¼ìš°ì € ê²½ê³ )
kubectl patch certificate backstage-tls -n backstage \
  --type='json' \
  -p='[{"op": "replace", "path": "/spec/issuerRef/name", "value":"letsencrypt-staging"}]'

# ì¸ì¦ì„œ ì¬ë°œê¸‰ í™•ì¸
kubectl get certificate -n backstage -w
```

**ì˜µì…˜ 2: ëŒ€ê¸°**

Let's Encrypt Rate Limit:
- **Domainë‹¹**: 50 certificates / ì£¼
- **ì¬ë°œê¸‰**: 5 certificates / ì£¼

```bash
# 1ì‹œê°„ í›„ ì¬ì‹œë„
kubectl delete certificate -A --all
# Argo CDê°€ ìë™ìœ¼ë¡œ ì¬ìƒì„±
```

### 5.3 Certificate Issuer ì—†ìŒ

#### ì¦ìƒ

```bash
$ kubectl describe certificate backstage-tls -n backstage
Error: cert-manager.io "letsencrypt-production" not found
```

#### ì›ì¸

Cert-Managerì˜ ClusterIssuerê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.

#### í•´ê²° ë°©ë²•

```bash
# 1. ClusterIssuer í™•ì¸
kubectl get clusterissuer

# 2. cert-manager Application ì¬ë™ê¸°í™”
kubectl delete application -n argocd cert-manager-$(yq '.cluster_name' config.yaml)

# 3. ClusterIssuer ìƒì„± í™•ì¸
kubectl get clusterissuer
# NAME                      READY   AGE
# letsencrypt-production    True    30s
# letsencrypt-staging       True    30s
```

---

## 6. Keycloak & PostgreSQL ë¬¸ì œ

### 6.1 Keycloak Pod - ImagePullBackOff (bitnami ì´ë¯¸ì§€)

#### ì¦ìƒ

```bash
$ kubectl get pods -n keycloak
NAME          READY   STATUS         RESTARTS   AGE
keycloak-0    0/1     ErrImagePull   0          5m

$ kubectl describe pod keycloak-0 -n keycloak
Failed to pull image "docker.io/bitnami/keycloak:latest":
manifest for docker.io/bitnami/keycloak:latest not found
```

#### ì›ì¸

Bitnamiê°€ ë ˆê±°ì‹œ ì´ë¯¸ì§€ë¥¼ `bitnamilegacy` ë ˆì§€ìŠ¤íŠ¸ë¦¬ë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤.

#### í•´ê²° ë°©ë²•

```bash
# 1. values.yaml í™•ì¸
cat packages/keycloak/values.yaml | grep -A 2 "image:"

# 2. ìˆ˜ì • (ì•„ì§ ì•ˆë˜ì–´ ìˆë‹¤ë©´)
vi packages/keycloak/values.yaml
```

**ì˜¬ë°”ë¥¸ ì„¤ì •:**

```yaml
image:
  registry: docker.io
  repository: bitnamilegacy/keycloak  # bitnami â†’ bitnamilegacy
  tag: latest

postgresql:
  enabled: true
  image:
    registry: docker.io
    repository: bitnamilegacy/postgresql  # bitnami â†’ bitnamilegacy
    tag: latest
```

```bash
# 3. Git commit & push
git add packages/keycloak/values.yaml
git commit -m "Fix: Use bitnamilegacy registry for Keycloak and PostgreSQL"
git push origin main

# 4. Application ì¬ë™ê¸°í™”
kubectl delete application -n argocd keycloak-$(yq '.cluster_name' config.yaml)

# 5. Pod ìƒì„± í™•ì¸
kubectl get pods -n keycloak -w
```

### 6.2 Keycloak Config Job ì‹¤íŒ¨

#### ì¦ìƒ

```bash
$ kubectl get pods -n keycloak
NAME                                READY   STATUS    RESTARTS   AGE
keycloak-0                          1/1     Running   0          5m
keycloak-user-sso-config-job-xxx    0/1     Error     3          5m

$ kubectl logs -n keycloak keycloak-user-sso-config-job-xxx
error: exec requires the binary 'kubectl' to be present in $PATH
```

#### ì›ì¸

Config Jobì´ kubectl ë°”ì´ë„ˆë¦¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (ì´ë¯¸ ìˆ˜ì •ë˜ì–´ ìˆì–´ì•¼ í•¨).

#### í•´ê²° ë°©ë²•

```bash
# 1. Job ë§¤ë‹ˆí˜ìŠ¤íŠ¸ í™•ì¸
cat packages/keycloak/manifests/user-sso-config-job.yaml | \
  grep "https://dl.k8s.io"

# ì˜¬ë°”ë¥¸ URL (stable version):
# https://dl.k8s.io/release/stable.txt

# 2. Job ì¬ì‹¤í–‰
kubectl delete job -n keycloak keycloak-user-sso-config-job

# Argo CDê°€ ìë™ìœ¼ë¡œ ì¬ìƒì„±

# 3. ì™„ë£Œ í™•ì¸
kubectl get job -n keycloak
# keycloak-user-sso-config-job   1/1           30s        2m
```

---

## 7. DNS ë¬¸ì œ

### 7.1 DNS ë ˆì½”ë“œ ìƒì„± ì•ˆë¨

#### ì¦ìƒ

```bash
$ dig myapp.example.com +short
# ì¶œë ¥ ì—†ìŒ (ë ˆì½”ë“œ ì—†ìŒ)
```

#### ì›ì¸

External DNSê°€ Route53 ë ˆì½”ë“œë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.

#### í•´ê²° ë°©ë²•

```bash
# 1. Ingress ADDRESS í™•ì¸ (ALB ìƒì„± ì™„ë£Œ í•„ìš”)
kubectl get ingress -A
# ADDRESS ì»¬ëŸ¼ì— ALB DNSê°€ ìˆì–´ì•¼ í•¨

# 2. External DNS ë¡œê·¸ í™•ì¸
kubectl logs -n external-dns deployment/external-dns --tail=100

# 3. External DNSê°€ Ingressë¥¼ ì¸ì‹í–ˆëŠ”ì§€ í™•ì¸
kubectl logs -n external-dns deployment/external-dns | \
  grep "CREATE\|UPDATE" | grep myapp.example.com

# 4. External DNS ì¬ì‹œì‘
kubectl rollout restart deployment external-dns -n external-dns

# 5. Route53 ë ˆì½”ë“œ í™•ì¸ (AWS Console ë˜ëŠ” CLI)
aws route53 list-resource-record-sets \
  --hosted-zone-id $(yq '.route53_hosted_zone_id' config.yaml) \
  --query "ResourceRecordSets[?Name=='myapp.example.com.']"
```

### 7.2 External DNS IAM ê¶Œí•œ ë¶€ì¡±

#### ì¦ìƒ

```bash
$ kubectl logs -n external-dns deployment/external-dns
AccessDenied: User: arn:aws:sts::123456789012:assumed-role/xxx
is not authorized to perform: route53:ChangeResourceRecordSets
```

#### ì›ì¸

External DNS ServiceAccountì˜ IAM Roleì— Route53 ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.

#### í•´ê²° ë°©ë²•

```bash
# 1. ServiceAccount IAM Role í™•ì¸
kubectl get sa external-dns -n external-dns -o yaml | \
  grep eks.amazonaws.com/role-arn

# 2. IAM Policy í™•ì¸
# í•„ìš”í•œ ê¶Œí•œ: route53:ChangeResourceRecordSets, route53:ListResourceRecordSets, route53:ListHostedZones

# 3. í´ëŸ¬ìŠ¤í„° ì¬ìƒì„± (ê¶Œí•œ í¬í•¨)
# ë˜ëŠ” eksctlë¡œ IAM ServiceAccount ì¬ìƒì„±
```

---

## 8. Argo CD ë¬¸ì œ

### 8.1 Applications ìƒì„± ì•ˆë¨

#### ì¦ìƒ

```bash
$ kubectl get applications -n argocd
NAME                              SYNC STATUS   HEALTH STATUS
addons-appset-pr-xxx              Synced        Healthy
# ë‚˜ë¨¸ì§€ Applications ì—†ìŒ (12ê°œê°€ ìˆì–´ì•¼ í•¨)
```

#### ì›ì¸ 1: hub-cluster-secret ì—†ìŒ

```bash
# Secret í™•ì¸
kubectl get secrets -n argocd -l argocd.argoproj.io/secret-type=cluster

# í•´ê²° ë°©ë²•ì€ "3.3 hub-cluster-secret ìƒì„± ì•ˆë¨" ì°¸ê³ 
```

#### ì›ì¸ 2: ApplicationSet Generator ì˜¤ë¥˜

```bash
# ApplicationSet ë¡œê·¸ í™•ì¸
kubectl logs -n argocd deployment/argocd-applicationset-controller

# ApplicationSet ìƒíƒœ í™•ì¸
kubectl describe applicationset -n argocd addons-appset-pr-xxx
```

### 8.2 Application OutOfSync

#### ì¦ìƒ

```bash
$ kubectl get applications -n argocd
NAME                      SYNC STATUS   HEALTH STATUS
backstage-xxx             OutOfSync     Healthy
```

#### í•´ê²° ë°©ë²•

```bash
# ìˆ˜ë™ ë™ê¸°í™”
kubectl patch application backstage-xxx -n argocd \
  --type json \
  -p='[{"op": "replace", "path": "/operation", "value": {"sync": {"syncOptions": ["CreateNamespace=true"], "prune": true}}}]'

# ë˜ëŠ” Argo CD UIì—ì„œ SYNC ë²„íŠ¼ í´ë¦­
```

### 8.3 Argo CD UI ì ‘ì† ì•ˆë¨

#### ì¦ìƒ

```bash
# Port forwardëŠ” ë˜ì§€ë§Œ UI ì ‘ì† ì‹œ 502 Bad Gateway
kubectl port-forward -n argocd svc/argocd-server 8080:80
```

#### í•´ê²° ë°©ë²•

```bash
# 1. argocd-server Pod ìƒíƒœ í™•ì¸
kubectl get pods -n argocd -l app.kubernetes.io/name=argocd-server

# 2. Pod ì¬ì‹œì‘
kubectl rollout restart deployment argocd-server -n argocd

# 3. ë¡œê·¸ í™•ì¸
kubectl logs -n argocd -l app.kubernetes.io/name=argocd-server
```

---

## 9. ì¼ë°˜ì ì¸ ë””ë²„ê¹… ë°©ë²•

### 9.1 Pod ë¬¸ì œ ë””ë²„ê¹…

```bash
# 1. Pod ìƒíƒœ í™•ì¸
kubectl get pods -n NAMESPACE

# 2. Pod ìƒì„¸ ì •ë³´ (Events í™•ì¸)
kubectl describe pod POD_NAME -n NAMESPACE

# 3. Pod ë¡œê·¸ í™•ì¸
kubectl logs POD_NAME -n NAMESPACE -f

# 4. ì´ì „ ì»¨í…Œì´ë„ˆ ë¡œê·¸ (CrashLoopBackOff ì‹œ)
kubectl logs POD_NAME -n NAMESPACE --previous

# 5. Pod ë‚´ë¶€ ì ‘ì†
kubectl exec -it POD_NAME -n NAMESPACE -- /bin/sh
# ë˜ëŠ”
kubectl exec -it POD_NAME -n NAMESPACE -- /bin/bash
```

### 9.2 Argo CD Application ë””ë²„ê¹…

```bash
# 1. Application ìƒíƒœ í™•ì¸
kubectl get application APP_NAME -n argocd -o yaml

# 2. ë™ê¸°í™” ìƒíƒœ í™•ì¸
kubectl describe application APP_NAME -n argocd

# 3. Application ì¬ë™ê¸°í™”
kubectl delete application APP_NAME -n argocd
# Argo CDê°€ ìë™ìœ¼ë¡œ ì¬ìƒì„± (ApplicationSet ì‚¬ìš© ì‹œ)

# 4. ê°•ì œ Hard Refresh
kubectl annotate application APP_NAME -n argocd \
  argocd.argoproj.io/refresh=hard --overwrite
```

### 9.3 ì´ë²¤íŠ¸ í™•ì¸

```bash
# íŠ¹ì • ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ ìµœê·¼ ì´ë²¤íŠ¸
kubectl get events -n NAMESPACE --sort-by='.lastTimestamp' | tail -20

# ì „ì²´ ì´ë²¤íŠ¸ (Warningë§Œ)
kubectl get events -A --field-selector type=Warning --sort-by='.lastTimestamp'
```

### 9.4 ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸

```bash
# ë…¸ë“œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
kubectl top nodes

# Pod ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
kubectl top pods -A --sort-by=memory

# íŠ¹ì • ë„¤ì„ìŠ¤í˜ì´ìŠ¤
kubectl top pods -n NAMESPACE
```

### 9.5 ë„¤íŠ¸ì›Œí¬ ë””ë²„ê¹…

```bash
# DNS í…ŒìŠ¤íŠ¸ Pod ì‹¤í–‰
kubectl run dnsutils --image=gcr.io/kubernetes-e2e-test-images/dnsutils:1.3 \
  --command -- sleep 3600

# DNS í…ŒìŠ¤íŠ¸
kubectl exec -it dnsutils -- nslookup kubernetes.default
kubectl exec -it dnsutils -- nslookup backstage.backstage.svc.cluster.local

# ì‚­ì œ
kubectl delete pod dnsutils
```

### 9.6 Persistent Data ì‚­ì œ (ì™„ì „ ì¬ì„¤ì¹˜)

```bash
# ì£¼ì˜: ëª¨ë“  ë°ì´í„° ì‚­ì œë¨!

# 1. PVC ì‚­ì œ
kubectl delete pvc -n keycloak --all
kubectl delete pvc -n backstage --all

# 2. Secrets ì‚­ì œ
kubectl delete secret -n keycloak --all
kubectl delete secret -n backstage --all
kubectl delete secret -n argocd --all

# 3. Applications ì¬ìƒì„±
kubectl delete applications -n argocd --all
```

---

## 10. ìœ ìš©í•œ ìŠ¤í¬ë¦½íŠ¸

### ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash

echo "=== Applications Status ==="
kubectl get applications -n argocd -o custom-columns='NAME:.metadata.name,SYNC:.status.sync.status,HEALTH:.status.health.status'

echo -e "\n=== Pods Not Running ==="
kubectl get pods -A | grep -v "Running\|Completed\|NAMESPACE"

echo -e "\n=== Ingresses ==="
kubectl get ingress -A

echo -e "\n=== Certificates ==="
kubectl get certificate -A

echo -e "\n=== ExternalSecrets ==="
kubectl get externalsecret -A

echo -e "\n=== Recent Events (Warnings) ==="
kubectl get events -A --field-selector type=Warning --sort-by='.lastTimestamp' | tail -10
```

### ë¹ ë¥¸ ì¬ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash

# ì£¼ìš” ì„œë¹„ìŠ¤ ì¬ì‹œì‘
kubectl rollout restart deployment backstage -n backstage
kubectl rollout restart deployment external-secrets -n external-secrets
kubectl rollout restart deployment external-dns -n external-dns
kubectl rollout restart statefulset keycloak -n keycloak
kubectl rollout restart deployment argocd-server -n argocd
kubectl rollout restart deployment argocd-repo-server -n argocd

echo "All services restarted. Wait 2-3 minutes for all pods to be ready."
```

---

## 11. ë„ì›€ì´ í•„ìš”í•œ ê²½ìš°

### ì •ë³´ ìˆ˜ì§‘

ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ë‹¤ìŒ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”:

```bash
# 1. ì „ì²´ Applications ìƒíƒœ
kubectl get applications -n argocd -o yaml > applications.yaml

# 2. ëª¨ë“  Pods ìƒíƒœ
kubectl get pods -A -o wide > pods.txt

# 3. ìµœê·¼ ì´ë²¤íŠ¸
kubectl get events -A --sort-by='.lastTimestamp' > events.txt

# 4. ë¬¸ì œ ìˆëŠ” Pod ë¡œê·¸
kubectl logs POD_NAME -n NAMESPACE > pod.log

# 5. config.yaml (ë¯¼ê°í•œ ì •ë³´ ì œê±° í›„)
cat config.yaml > config-sanitized.yaml
```

### GitHub Issues

ë¬¸ì œê°€ í•´ê²°ë˜ì§€ ì•Šìœ¼ë©´ [GitHub Issues](https://github.com/cnoe-io/reference-implementation-aws/issues)ì— ë‹¤ìŒ ì •ë³´ì™€ í•¨ê»˜ ë¬¸ì˜í•˜ì„¸ìš”:

- ë¬¸ì œ ì„¤ëª…
- ì¬í˜„ ë‹¨ê³„
- ìˆ˜ì§‘í•œ ë¡œê·¸ ë° ìƒíƒœ ì •ë³´
- AWS ë¦¬ì „ ë° EKS ë²„ì „

---

**ì´ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œëŠ” ì‹¤ì œ ë°°í¬ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìœ¼ë©°, ê³„ì† ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.** ğŸ› ï¸
